{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- p. 247 Probability_statistics_finance_Rachev -->\n",
    "<!-- p. 194 Probability_Statistics_for_Engineers_Scientists_Walpole -->\n",
    "<!-- p. 353 Introduction_to_Probability_Blitzstein.pdf. Good discussion Beta distribution -->\n",
    "<!-- add negative binomial, multinomial distributions -->\n",
    "\n",
    "# Useful Distributions\n",
    "\n",
    "## Normal Distribution\n",
    "\n",
    "\n",
    "\n",
    "Without a doubt, the normal (Gaussian) distribution is the most\n",
    "important and foundational probability distribution. The one-dimensional form\n",
    "is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x) =\\frac{e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}}{\\sqrt{2\\pi\\sigma^2 } }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where $\\mathbb{E}(x)=\\mu$ and $\\mathbb{V}(x)=\\sigma^2$.  The\n",
    "multidimensional version for $\\mathbf{x}\\in \\mathbb{R}^n$ is the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(\\mathbf{x}) = \\frac{1}{\\det(2\\pi \\mathbf{R})^{\\frac{1}{2}}} e^{-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})^T \\mathbf{R}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where $\\mathbf{R}$ is the covariance matrix with entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "R_{i,j} = \\mathbb{E}\\left[ (x_i-\\bar{x_i})(x_j-\\bar{x_j}) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A key property of the normal distribution is that it is completely\n",
    "specified by its first two moments. Another key property is that \n",
    "the normal distribution is preserved under linear tranformations. \n",
    "For example,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{y} = \\mathbf{A x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " means $\\mathbf{y}\\sim \\mathcal{N}(\\mathbf{A x},\\mathbf{A R_x}\n",
    "\\mathbf{A}^T)$. This means that it is easy to do linear algebra and matrix\n",
    "operations with normal distributed random variables.   There are many intuitive\n",
    "geometric relationships that are preserved with normal distributed random\n",
    "variables, as discussed in the Gauss-Markov chapter. \n",
    "\n",
    "## Multinomial Distribution\n",
    "\n",
    "\n",
    "<!-- see TheoPort p. 308 -->\n",
    "\n",
    "\n",
    "The Multinomial distribution generalized the Binomial distribution.\n",
    "Recall that the Binomial distribution characterizes the number of heads obtained \n",
    "in $n$ trials.\n",
    "Consider the problem of $n$ balls to be  divided among $r$  available bins\n",
    "where each bin may accommodate more than one ball. For example, suppose\n",
    "$n=10$ and and $r=3$, then one possible valid configuration is\n",
    "$\\mathbf{N}_{10}=[3,3,4]$. The probability that a ball lands in the\n",
    "$i^{th}$ bin is $p_i$, where $\\sum p_i=1$. The Multinomial distribution\n",
    "characterizes the probability distribution of $\\mathbf{N}_n$.  The Binomial\n",
    "distribution is a special case of the Multinomial distribution with $n=2$. The\n",
    "Multinomial distribution is implmented in the `scipy.stats` module as shown\n",
    "below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multinomial\n",
    "rv = multinomial(10,[1/3]*3)\n",
    "rv.rvs(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that the sum across the columns is always $n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rv.rvs(10).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To derive the probability mass function, we define the *occupancy vector*,\n",
    "$\\mathbf{e}_i\\in \\mathbb{R}^r$ which is a binary vector with exactly one\n",
    "non-zero component (i.e., a unit vector). Then, the $\\mathbf{N}_n$ vector can\n",
    "be written as the sum of $n$ vectors $\\mathbf{X}$, each drawn from the set\n",
    "$\\lbrace \\mathbf{e}_j \\rbrace_{j=1}^r$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{N}_n = \\sum_{i=1}^n  \\mathbf{X}_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where the probability $\\mathbb{P}(\\mathbf{X}=\\mathbf{e}_j)=p_j$.  Thus,\n",
    "$\\mathbf{N}_n$ has a discrete distribution over the set of vectors with \n",
    "non-negative components that sum to $n$. Because the $\\mathbf{X}$ \n",
    "vectors are independent and identically distributed, the \n",
    "probability of any particular $\\mathbf{N}_n=[ x_1,x_2,\\cdots,x_r ]^\\top=\\mathbf{x}$ is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(\\mathbf{N}_n=x) = C_n p_1^{x_1} p_2^{x_2}\\cdots p_r^{x_r}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where $C_n$ is a combinatorial factor that accounts for all the ways\n",
    "a component can sum to $x_j$. Consider that there are $\\binom{n}{x_1}$ ways\n",
    "that the first component can be chosen. This leaves $n-x_1$ balls left for the\n",
    "rest of the vector components. Thus, the second component  has\n",
    "$\\binom{n-x_1}{x_2}$ ways to pick a ball. Following the same pattern, the\n",
    "third component has $\\binom{n-x_1-x_2}{x_3}$ ways and so forth,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "C_n = \\binom{n}{x_1}\\binom{n-x_1}{x_2} \\binom{n-x_1-x_2}{x_3} \\cdots \\binom{n-x_1-x_2-\\cdots-x_{r-1}}{x_r}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  simplifies to the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "C_n = \\frac{n!}{x_1! \\cdots x_r!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Thus, the probability mass function for the Multinomial distribution is the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(\\mathbf{N}_n=x) = \\frac{n!}{x_1! \\cdots x_r!} p_1^{x_1} p_2^{x_2}\\cdots p_r^{x_r}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The expectation of this distribution is the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}(\\mathbf{N}_n) = \\sum_{i=1}^n \\mathbb{E}(X_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " by the linearity of the expectation. Then,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}(X_i) = \\sum_{j=1}^r p_j \\mathbf{e}_j = \\mathbf{I}\\mathbf{p}=\\mathbf{p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where $p_j$ are the components of the vector $\\mathbf{p}$ and \n",
    "$\\mathbf{I}$ is the identity matrix. Then, because this is the same for any $X_i$,\n",
    "we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}(\\mathbf{N}_n) = n \\mathbf{p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the covariance of $\\mathbf{N}_n$, we need to compute the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textrm{Cov}(\\mathbf{N}_n) = \\mathbb{E}\\left(\\mathbf{N}_n \\mathbf{N}_n^\\top\\right) - \\mathbb{E}(\\mathbf{N}_n) \\mathbb{E}(\\mathbf{N}_n)^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For the first term on the right, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}\\left(\\mathbf{N}_n \\mathbf{N}_n^\\top\\right)=\\mathbb{E}\\left((\\sum_{i=1}^n X_i)(\\sum_{j=1}^n X_j^\\top) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and for $i=j$, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}(X_i X_i^\\top) = \\textrm{diag}(\\mathbf{p})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and for $i\\neq j$, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}(X_i X_j^\\top) = \\mathbf{p}\\mathbf{p}^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that this term has elements on the diagonal. Then, combining the\n",
    "above two equations gives the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}(\\mathbf{N}_n\\mathbf{N}_n^\\top) = n \\textrm{diag}(\\mathbf{p}) + (n^2-n) \\mathbf{p}\\mathbf{p}^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, we can assemble the covariance matrix,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textrm{Cov}(\\mathbf{N}_n) = n \\textrm{diag}(\\mathbf{p}) + (n^2-n) \\mathbf{p}\\mathbf{p}^\\top - n^2 \\mathbf{p} \\mathbf{p}^\\top = n \\textrm{diag}(\\mathbf{p})-n \\mathbf{p} \\mathbf{p}^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Specifically, the off-diagonal terms are $n p_i p_j$ and the diagonal terms are $n p_i (1-p_i)$.\n",
    "\n",
    "## Chi-Square Distribution\n",
    "\n",
    "\n",
    "\n",
    "The $\\chi^2$ distribution appears in many different contexts so it's worth\n",
    "understanding.  Suppose we have $n$ independent random variables\n",
    "$X_i$ such that $X_i\\sim \\mathcal{N}(0,1)$.  We are interested in the following\n",
    "random variable $R = \\sqrt{\\sum_i X_i^2}$. The joint probability density of\n",
    "$X_i$ is the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f_{\\mathbf{X}}(X) = \\frac{e^{-\\frac{1}{2}\\sum_i X_i^2}}{(2\\pi)^{\\frac{n}{2}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where the $\\mathbf{X}$ represents a vector of $X_i$ random variables. You \n",
    "can think of $R$ as the radius of an $n$-dimensional sphere. The volume of \n",
    "this sphere is given by the the following formula,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "V_n(R) = \\frac{\\pi^{\\frac{n}{2}}}{\\Gamma(\\frac{n}{2}+1)} R^n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To reduce the amount of notation we define,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A := \\frac{\\pi^{\\frac{n}{2}}}{\\Gamma(\\frac{n}{2}+1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The differential of this volume is the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "dV_n(R)= n A R^{n-1} dR\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In term of the $X_i$ coordinates, the probability (as always) \n",
    "integrates out to one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\int f_{\\mathbf{X}}(\\mathbf{X}) dV_n(\\mathbf{X}) = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In terms of $R$, the change of variable provides,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\int f_{\\mathbf{X}}(R) n A R^{n-1} dR\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Thus,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f_R(R):=f_{\\mathbf{X}}(R)  = n A R^{n-1}\\frac{e^{-\\frac{1}{2}R^2}}{(2\\pi)^{\\frac{n}{2}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " But we are interested in the distribution $Y=R^2$. Using the same\n",
    "technique again,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\int f_{R}(R) dR =\\int f_{R}(\\sqrt{Y}) \\frac{dY}{2\\sqrt{Y}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Finally,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f_Y(Y) := n A Y^\\frac{n-1}{2}\\frac{e^{-\\frac{1}{2}Y}}{(2\\pi)^{\\frac{n}{2}}} \\frac{1}{2\\sqrt{Y}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then, finally substituting back in $A$ gives the $\\chi^2$ distribution with $n$ degrees of freedom,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f_Y(Y) = n \\frac{\\pi^{\\frac{n}{2}}}{\\Gamma(\\frac{n}{2}+1)} Y^{n/2-1}\\frac{e^{-\\frac{1}{2}Y}}{(2\\pi)^{\\frac{n}{2}}} \\frac{1}{2}= \\frac{2^{-\\frac{n}{2}-1} n }{\\Gamma \\left(\\frac{n}{2}+1\\right)}e^{-Y/2} Y^{\\frac{n}{2}-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Hypothesis testing is a common application of the $\\chi^2$\n",
    "distribution.  Consider Table [1](#tab:diagnosisTable) which tabulates the\n",
    "infection status of a certain population.  The hypothesis is that these data\n",
    "are distributed according to the multinomial distribution with the following\n",
    "rates for each group, $p_1=1/4$ (mild infection), $p_2=1/4$ (strong infection),\n",
    "and $p_3=1/2$ (no infection). Suppose $n_i$ is the count of persons in the\n",
    "$i^{th}$ column and $\\sum_{i} n_i=n=684$. Let $k$ denote the number of columns.\n",
    "Then, in order to apply the Central Limit Theorem, we want to sum the $n_i$\n",
    "random variables, but these all sum to $n$, a constant, which prohibits using\n",
    "the theorem. Instead, suppose we sum the $n_i$ variables up to $k-1$ terms. Then,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "z = \\sum_{i=1}^{k-1} n_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " is asymptotically normally distributed by the theorem with mean\n",
    "$\\mathbb{E}(z) = \\sum_{i=1}^{k-1} n p_i$. Using our previous results and notation \n",
    "for multinomial random variables, we can write this as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "z = [\\mathbf{1}_{k-1}^\\top,0]\\mathbf{N}_n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where $\\mathbf{1}_{k-1}$ is a vector of all ones of length $k-1$ and\n",
    "$\\mathbf{N}_n\\in \\mathbb{R}^{k}$. With this notation, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}(z )= n [\\mathbf{1}_{k-1}^\\top,0] \\mathbf{p} = \\sum_{i=1}^{k-1} n p_i = n(1-p_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can get the variance of $z$ using the same method,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{V}(z) =[\\mathbf{1}_{k-1}^\\top,0]\\textrm{Cov}(\\mathbf{N}_n)[\\mathbf{1}_{k-1}^\\top,0]^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " which gives,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{V}(z) =[\\mathbf{1}_{k-1}^\\top,0](n\\textrm{diag}(\\mathbf{p})-n\\mathbf{p}\\mathbf{p}^\\top )[\\mathbf{1}_{k-1}^\\top,0]^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The variance is then,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{V}(z) = n (1-p_k)p_k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " With the mean and variance established we can subtract the\n",
    "hypothesize mean for each column under the hypothesis and create the\n",
    "transformed variable,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "z^\\prime = \\sum_{i=1}^{k-1} \\frac{n_i-n p_i}{\\sqrt{n (1-p_k)p_k}} \\sim \\mathcal{N}(0,1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " by the Central Limit Theorem. Likewise,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum_{i=1}^{k-1} \\frac{(n_i-n p_i)^2}{n (1-p_k)p_k} \\sim \\chi_{k-1}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"tab:diagnosisTable\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{table}[]\n",
    "\\centering\n",
    "\\caption{Diagnosis Table}\n",
    "\\label{tab:diagnosisTable} \\tag{1}\n",
    "\\begin{tabular}{lllll}\n",
    "\\cline{1-4}\n",
    "\\multicolumn{1}{|l|}{Mild Infection} & \\multicolumn{1}{l|}{Strong Infection}  & \\multicolumn{1}{l|}{No infection} & \\multicolumn{1}{l|}{Total} &  \\\\ \\cline{1-4}\n",
    "\\multicolumn{1}{|c|}{128}            & \\multicolumn{1}{c|}{136}               & \\multicolumn{1}{c|}{420}           & \\multicolumn{1}{c|}{684}  & \\\\ \\cline{1-4}\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all that established, we can test the hypothesis that the data in the table \n",
    "follow the hypothesized multinomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "n = 684\n",
    "p1 = p2 = 1/4\n",
    "p3 = 1/2\n",
    "v = n*p3*(1-p3)\n",
    "z = (128-n*p1)**2/v + (136-n*p2)**2/v\n",
    "1-stats.chi2(2).cdf(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This value is very low and suggests that the hypothesized multinomial\n",
    "distribution is not a good one for this data. Note that this approximation only\n",
    "works when `n` is large in comparison to the number of columns in the table.\n",
    "\n",
    "## Poisson and Exponential Distributions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The Poisson distribution for a random variable $X$ represents a number of\n",
    "outcomes occurring in a given time interval ($t$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(x;\\lambda t) = \\frac{e^{-\\lambda t}(\\lambda t)^x}{x!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The Poisson distribution is closely related to the binomial\n",
    "distribution, $b(k;n,p)$ where $p$ is small and $n$ is large. That is, when\n",
    "there is a low-probability event but many trials, $n$. Recall that the binomial\n",
    "distribution is the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "b(k;n,p) =\\binom{n}{k} p^k (1-p)^{n-k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " for $k=0$ and taking the logarithm of both sides, we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\log b(0;n,p) = (1-p)^n = \\left( 1-\\frac{\\lambda}{n} \\right)^n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then, the Taylor expansion of this gives the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\log b(0;n,p) \\approx -\\lambda - \\frac{\\lambda^2}{2 n} - \\cdots\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For large $n$, this results in,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "b(0;n,p) \\approx e^{-\\lambda}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A similar argument for $k$ leads to the Poisson distribution.\n",
    "Conveniently, we have $\\mathbb{E}(X) = \\mathbb{V}(X)= \\lambda$. For example,\n",
    "suppose that the average number of vehicles passing under a toll-gate per hour\n",
    "is 3. Then, the probability that 6 vehicles pass under the gate in a given hour\n",
    "is $p(x=6;\\lambda t= 3) = \\frac{81}{30 e^3}\\approx 0.05$.\n",
    "\n",
    "The Poisson distribution is available from the `scipy.stats` module.\n",
    "The following code computes the last result,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "x = poisson(3)\n",
    "print(x.pmf(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Poisson distribution is important for applications involving reliability\n",
    "and queueing. The Poisson distribution is used to compute the probability of\n",
    "specific numbers of events during a particular time period. In many cases the\n",
    "time period ($X$) itself is the random variable. For example, we might be\n",
    "interested in understanding the time $X$ between arrivals of vehicles at a\n",
    "checkpoint. With the Poisson distribution, the probability of *no* events\n",
    "occurring in the span of time up to time $t$ is given by the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(0;\\lambda t) = e^{-\\lambda t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, suppose $X$ is the time to the first event. The \n",
    "probability that the length of time until the first event will exceed $x$ is \n",
    "given by the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(X>x) = e^{-\\lambda x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then, the cumulative distribution function is given by \n",
    "the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(0\\le X\\le x) = F_X (x) = 1-e^{- \\lambda x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Taking the derivative gives the *exponential* distribution,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f_X(x) = \\lambda e^{-\\lambda x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where $\\mathbb{E}(X) = 1/\\lambda $ and $\\mathbb{V}(X)=\\frac{1}{\\lambda^2}$.\n",
    "For example, suppose we want to know the probability of a certain \n",
    "component lasting beyond $T=10$ years where $T$ is modeled as a \n",
    "an exponential random variable with $1/\\lambda=5$ years. Then, we have\n",
    "$1-F_X(10) = e^{-2} \\approx 0.135 $.\n",
    "\n",
    "The exponential distribution is available in the `scipy.stats` module.  The\n",
    "following code computes the result of the example above. Note that the\n",
    "parameters are described in slightly different terms as above, as described in\n",
    "the corresponding documentation for `expon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import expon\n",
    "x = expon(0,5) # create random variable object\n",
    "print(1 - x.cdf(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamma Distribution\n",
    "\n",
    "\n",
    "\n",
    "We have previously discussed how the exponential distribution can be created\n",
    "from the Poisson events.  The exponential distribution has the *memoryless*\n",
    "property, namely,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(T>t_0+t\\vert T>t_0) = \\mathbb{P}(T>t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For example, given $T$ as the random variable representing the time\n",
    "until failure, this means that a component that has survived up through $t_0$\n",
    "has the same failure probability of lasting $t$ units beyond that point. To \n",
    "derive this result, it is easier to compute the complementary event,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(t_0<T<t_0+t\\vert T>t_0) = \\mathbb{P}(t_0<T<t_0+t) = e^{-\\lambda  t} \\left(e^{\\lambda  t}-1\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then, one minus this result shows the memoryless property, which,\n",
    "unrealistically, does not account for wear over the first $t$ hours. The\n",
    "*gamma* distribution can remedy this.\n",
    "\n",
    "Recall that the exponential distribution describes the time until the\n",
    "occurrence of a Poisson event, the random variable $X$ for the time\n",
    "until a specified number of Poisson events ($\\alpha$) is described by the\n",
    "*gamma* distribution. Thus, the exponential distribution is a special \n",
    "case of the gamma distribution when $\\alpha=1$ and $\\beta=1/\\lambda$. For $x>0$, \n",
    "the gamma distribution is the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x;\\alpha,\\beta)=\n",
    "\\frac{\\beta ^{-\\alpha } x^{\\alpha\n",
    "   -1} e^{-\\frac{x}{\\beta\n",
    "   }}}{\\Gamma (\\alpha )}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and $f(x;\\alpha,\\beta)=0$ when $x\\le 0$ and $\\Gamma$ is the gamma\n",
    "function. For example, suppose that vehicles passing under a gate follows a\n",
    "Poisson process, with an average of 5 vehicles passing per hour, what is the\n",
    "probability that at most an hour will have passed before 2 vehicles pass the\n",
    "gate? If $X$ is time in hours that transpires before the 2 vehicles pass, then\n",
    "we have $\\beta=1/5$ and $\\alpha=2$. The required probability $\\mathbb{P}(X<1)\n",
    "\\approx 0.96 $. The gamma distribution has $\\mathbb{E}(X) = \\alpha\\beta $ and\n",
    "$\\mathbb{V}(X)=\\alpha\\beta^2$\n",
    "\n",
    "The\n",
    "following code computes the result of the example above. Note that the\n",
    "parameters are described in slightly different terms as above, as described in\n",
    "the corresponding documentation for `gamma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import gamma\n",
    "x = gamma(2,scale=1/5) # create random variable object\n",
    "print(x.cdf(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta Distribution\n",
    "\n",
    "\n",
    "\n",
    "The uniform distribution assigns a single constant value \n",
    "over the unit interval. The Beta distribution generalizes this to\n",
    "a function over the unit interval. The probability density function \n",
    "of the Beta distribution is the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x ) = \\frac{1}{\\beta(a,b)} x^{a-1} (1-x)^{b-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\beta(a,b) = \\int_0^1 x^{a-1} (1-x)^{b-1} dx\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Note that $a=b=1$ yields the uniform distribution. In the \n",
    "special case for integers where $0\\le k\\le n$, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\int_0^1 \\binom{n}{k}x^k (1-x)^{n-k} dx = \\frac{1}{n+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To get this result without calculus, we can use an experiment by\n",
    "Thomas Bayes.  Start with $n$ white balls and one gray ball. Uniformly at\n",
    "random, toss them onto the unit interval. Let $X$ be the number of white balls\n",
    "to the left of the gray ball. Thus, $X\\in \\lbrace 0,1,\\ldots,n \\rbrace$. To\n",
    "compute $\\mathbb{P}(X=k)$, we condition on the probability of the position $B$\n",
    "of the gray ball, which is uniformly distributed over the unit interval\n",
    "($f(p)=1$). Thus, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(X=k) = \\int_0^1 \\mathbb{P}(X=k\\vert B=p) f(p) dp = \\int_0^1 \\binom{n}{k}p^k (1-p)^{n-k} dp\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, consider a slight variation on the experiment where we start\n",
    "with $n+1$ white balls and again toss them onto the unit interval and then\n",
    "later choose one ball at random to color gray. Using the same $X$ as before, by\n",
    "symmetry, because any one of the $n+1$ balls is equally likely to be chosen, we\n",
    "have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(X=k)=\\frac{1}{n+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " for $k\\in \\lbrace 0,1,\\ldots,n \\rbrace$. Both situations describe the\n",
    "same problem because it does not matter whether we paint the ball before or\n",
    "after we throw it. Setting the last two equations equal gives the desired\n",
    "result without using calculus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\int_0^1 \\binom{n}{k}p^k (1-p)^{n-k} dp =  \\frac{1}{n+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows where to get the Beta distribution from the `scipy` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "x = beta(1,1) # create random variable object\n",
    "print(x.cdf(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this experiment, it is not too surprising that there is an intimate\n",
    "relationship between the Beta distribution and binomial random variables.\n",
    "Suppose we want to estimate the probability of heads for coin-tosses using\n",
    "Bayesian inference. Using this approach, all unknown quantities are treated as\n",
    "random variables.  In this case, the probability of heads ($p$) is the unknown\n",
    "quantity that requires a *prior* distribution. Let us choose the Beta\n",
    "distribution as the prior distribution, $\\texttt{Beta}(a,b)$. Then,\n",
    "conditioning on $p$, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X\\vert p \\sim \\texttt{binom}(n,p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " which says that $X$ is conditionally  distributed as a binomial. To \n",
    "get the posterior probability, $f(p\\vert X=k)$, we have the following\n",
    "Bayes rule,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(p\\vert X=k) = \\frac{\\mathbb{P}(X=k\\vert p)f(p)}{\\mathbb{P}(X=k)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " with the corresponding denominator,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(X=k) = \\int_0^1 \\binom{n}{k}p^k (1-p)^{n-k}f(p) dp\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that unlike with our experiment before, $f(p)$ is not constant.\n",
    "Without substituting in all of the distributions,  we observe that the\n",
    "posterior is a function of $p$ which means that everything else that is not a\n",
    "function of $p$ is a constant.  This gives,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(p\\vert X=k) \\propto p^{a+k-1} (1-p)^{b+n-k-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " which is another Beta distribution with parameters $a+k,b+n-k$. This\n",
    "special relationship in which the beta prior probability distribution on $p$ on\n",
    "data that are conditionally binomial distributed  yields the posterior that is\n",
    "also binomial distributed is known as *conjugacy*. We say that the Beta\n",
    "distribution is the conjugate prior of the binomial distribution.\n",
    "\n",
    "## Dirichlet-multinomial Distribution\n",
    "\n",
    "\n",
    "\n",
    "The Dirichlet-multinomial distribution is a discrete multivariate distribution\n",
    "also known as the multivariate Polya distribution.  The Dirichlet-multinomial\n",
    "distribution arises in situations where the usual multinomial distribution is\n",
    "inadequate.  For example, if a multinomial distribution is used to model the\n",
    "number of balls that land in a set of bins and the multinomial parameter vector\n",
    "(i.e., probabilities of balls landing in particular bins) varies from trial to\n",
    "trial, then the Dirichlet distribution can be used to include variation in\n",
    "those probabilities because the Dirichlet distribution is defined over a\n",
    "simplex that describes the multinomial parameter vector.\n",
    "\n",
    "Specifically, suppose we have $K$ rival events, each with probability $\\mu_k$.\n",
    "Then, the probability of the vector $\\boldsymbol{\\mu}$ given that \n",
    "each event has been observed $\\alpha_k$ times  is the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(\\boldsymbol{\\mu}\\vert \\boldsymbol{\\alpha}) \\propto \\prod_{k=1}^K \\mu_k^{\\alpha_k-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where $0\\le\\mu_k\\le 1$ and $\\sum\\mu_k=1$. Note that this last sum is\n",
    "a constraint  that makes the distribution $K-1$ dimensional. The normalizing \n",
    "constant for this distribution is the multinomial Beta function,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textnormal{Beta}(\\boldsymbol{\\alpha})=\\frac{\\prod_{k=1}^K\\Gamma(\\alpha_k)}{\\Gamma(\\sum_{k=1}^K\\alpha_k)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The elements of the $\\boldsymbol{\\alpha}$ vector are also called\n",
    "*concentration* parameters. As before, the Dirichlet \n",
    "distribution can be found in the `scipy.stats` module,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import dirichlet\n",
    "d = dirichlet([ 1,1,1 ])\n",
    "d.rvs(3) # get samples from distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that each of the rows sums to one. This is because of the\n",
    "$\\sum\\mu_k=1$ constraint. We can generate more samples and plot this \n",
    "using `Axes3D` in Matplotlib in [Figure](#fig:Dirichlet_001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.pyplot import subplots\n",
    "x = d.rvs(1000)\n",
    "fig, ax = subplots(subplot_kw=dict(projection='3d'))\n",
    "_=ax.scatter(x[:,0],x[:,1],x[:,2],marker='o',alpha=.2)\n",
    "ax.view_init(30, 30) # elevation, azimuth\n",
    "ax.set_aspect(1)\n",
    "_=ax.set_xlabel(r'$\\mu_1$')\n",
    "_=ax.set_ylabel(r'$\\mu_2$')\n",
    "_=ax.set_zlabel(r'$\\mu_3$')\n",
    "fig.savefig('fig-probability/Dirichlet_001.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:FIGURE: [fig-probability/Dirichlet_001.png, width=500 frac=0.85] One thousand samples from a Dirichlet distribution with $\\boldsymbol{\\alpha} = [1,1,1]$  <div id=\"fig:Dirichlet_001\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:Dirichlet_001\"></div>\n",
    "\n",
    "<p>One thousand samples from a Dirichlet distribution with $\\boldsymbol{\\alpha} = [1,1,1]$</p>\n",
    "<img src=\"fig-probability/Dirichlet_001.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "Notice that the generated samples lie on the triangular simplex shown. The\n",
    "corners of the triangle correspond to each of the components in the\n",
    "$\\boldsymbol{\\mu}$.  Using, a non-uniform $\\boldsymbol{\\alpha}=[2,3,4]$ vector,\n",
    "we can visualize the probability density function using the `pdf` method on the\n",
    "`dirichlet` object as shown in [Figure](#fig:Dirichlet_002). By choosing the\n",
    "$\\boldsymbol{\\alpha}\\in \\mathbb{R}^3$, the peak of the density function can be\n",
    "moved within the corresponding triangular simplex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pylab import cm\n",
    "X,Y = np.meshgrid(np.linspace(.01,1,50),np.linspace(.01,1,50))\n",
    "d = dirichlet([2,3,4])\n",
    "idx=(X+Y<1)\n",
    "f=d.pdf(np.vstack([X[idx],Y[idx],1-X[idx]-Y[idx]]))\n",
    "Z = idx*0+ np.nan\n",
    "Z[idx] = f\n",
    "fig,ax=subplots()\n",
    "_=ax.contourf(X,Y,Z,cmap=cm.viridis)\n",
    "ax.set_aspect(1)\n",
    "_=ax.set_xlabel('x',fontsize=18)\n",
    "_=ax.set_ylabel('y',fontsize=18)\n",
    "fig.savefig('fig-probability/Dirichlet_002.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:FIGURE: [fig-probability/Dirichlet_002.png, width=500 frac=0.85] Probability density function for the Dirichlet distribution with $\\boldsymbol{\\alpha}=[2,3,4]$  <div id=\"fig:Dirichlet_002\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:Dirichlet_002\"></div>\n",
    "\n",
    "<p>Probability density function for the Dirichlet distribution with $\\boldsymbol{\\alpha}=[2,3,4]$</p>\n",
    "<img src=\"fig-probability/Dirichlet_002.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "We have seen that the Beta distribution generalizes the uniform distribution\n",
    "over the unit interval. Likewise, the Dirichlet distribution generalizes the\n",
    "Beta distribution over a vector with components in the unit interval. Recall\n",
    "that binomial distribution and the Beta distribution form a conjugate pair \n",
    "for Bayesian inference because with $p\\sim \\textnormal{Beta} $,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X\\vert p \\sim \\textnormal{Binomial}(n,p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " That is, the data conditioned on $p$, is binomial distributed.\n",
    "Analogously, the multinomial distribution and the Dirichlet distribution also\n",
    "form such a conjugate pair with multinomial parameter $p\\sim\n",
    "\\textnormal{Dirichlet} $,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X\\vert p \\sim \\textnormal{multinomial}(n,p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For this reason, the Dirichlet-multinomial distribution is popular in\n",
    "machine learning text processing because non-zero probabilities can be assigned\n",
    "to words not specifically contained in specific documents, which helps\n",
    "generalization performance.\n",
    "\n",
    "\n",
    "## Negative Binomial Distribution\n",
    "\n",
    "\n",
    "The negative binomial distribution is used to characterize the number\n",
    "of trials until a specified number of  failures ($r$) occurs.  For\n",
    "example, suppose `1` indicates failure and `0` indicates success. Then\n",
    "the negative binomial distribution characterizes the probability of a\n",
    "`k=6` long sequence that has two (`r=2`) failures, with the sequence\n",
    "terminating in a failure (e.g., `001001`) with\n",
    "$\\mathbb{P}(1)=1/3$.  The length of the sequence is `6`, so for the\n",
    "negative binomial distribution, $\\mathbb{P}(6-2)=\\frac{80}{729}$.\n",
    "\n",
    "The probability mass function is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(k) = \\binom{n+k-1}{n-1} p^n (1-p)^k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where $p$ is the probability of failure. The mean and\n",
    "variance of this distribution is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}(k) =\\frac{n (1-p)}{p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{V}(k) = \\frac{n (1-p)}{p^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The following simulation shows an example\n",
    "sequence generated for the negative binomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "n=2    # num of failures\n",
    "p=1/3  # prob of failure\n",
    "nc = 0 # counter\n",
    "seq= []\n",
    "while nc< n:\n",
    "    v,=random.choices([0,1],[1-p,p])\n",
    "    seq.append(v)\n",
    "    nc += (v == 1)\n",
    "\n",
    "seq,len(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Keep in mind that the negative binomial distribution characterizes \n",
    "the family of such sequences with the specified number of failures.\n",
    "\n",
    "## Negative Multinomial Distribution\n",
    "\n",
    "\n",
    "The discrete negative multinomial distribution is an extension of the negative\n",
    "binomial distribution to account for more than two possible outcomes. That is,\n",
    "there are other alteratives whose respective probabilities sum to one less the\n",
    "failure probability,  $p_{f} = 1-\\sum_{k=1}^n p_i$.  For example, a random\n",
    "sample from this distribution with parameters $n=2$ (number of observed\n",
    "failures) and with $p_a= \\frac{1}{3}, p_b=\\frac{1}{2}$ means that the failure\n",
    "probability, $p_f=\\frac{1}{6}$. Thus, a sample from this distribution like\n",
    "$[ 2,9]$ means that `2` of the $a$ objects were observed in the\n",
    "sequence, `9` of the $b$ objects were observed, and there were two failure\n",
    "symbols (say, `F`) with one of them at the end of the sequence.\n",
    "\n",
    "The probability mass function is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(\\mathbf{k})= (n)_{\\sum_{i=0}^m k_i} p_f^{n} \\prod_{i=1}^m \\frac{p_i^{k_i}}{k_i!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where $p_f$ is the probability of failure and the other $p_i$ terms\n",
    "are the probabilities of the other alternatives in the sequence. The \n",
    "$(a)_n$ notation is the rising factorial function (e.g., $a_3 = a (a+1)(a+2)$).\n",
    "The mean and variance of this distribution is the\n",
    "following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}(\\mathbf{k}) =\\frac{n}{p_f} \\mathbf{p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{V}(k) = \\frac{n}{p_f^2} \\mathbf{p} \\mathbf{p}^T + \\frac{n}{p_f}\\diag(\\mathbf{p})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The following simulation shows the sequences generated for the\n",
    "negative multinomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "n=2                   # num of failure items\n",
    "p=[1/3,1/2]           # prob of other non-failure items\n",
    "items = ['a','b','F'] # F marks failure item\n",
    "nc = 0                # counter\n",
    "seq= []\n",
    "while nc< n:\n",
    "    v,=random.choices(items,p+[1-sum(p)])\n",
    "    seq.append(v)\n",
    "    nc += (v == 'F')\n",
    "\n",
    "c=Counter(seq)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The values of the `Counter` dictionary above are the $\\mathbf{k}$ \n",
    "vectors in the probability mass function for the negative multinomial distribution. \n",
    "Importantly, these are not the probabilities of a particular sequence, but \n",
    "of a family of sequences with the same corresponding `Counter` values. \n",
    "The probability mass function implemented in Python is the following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.special import factorial\n",
    "import numpy as np\n",
    "def negative_multinom_pdf(p,n):\n",
    "    assert len(n) == len(p)\n",
    "    term = [i**j for i,j in zip(p,n)]\n",
    "    num=np.prod(term)*(1-sum(p))*factorial(sum(n))\n",
    "    den = np.prod([factorial(i) for i in n])\n",
    "    return num/den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluating this with the prior `Counter` result,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negative_multinom_pdf([1/3,1/2],[c['a'],c['b']])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
