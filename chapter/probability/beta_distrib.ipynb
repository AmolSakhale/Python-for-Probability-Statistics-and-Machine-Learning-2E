{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uniform distribution assigns a single constant value \n",
    "over the unit interval. The Beta distribution generalizes this to\n",
    "a function over the unit interval. The probability density function \n",
    "of the Beta distribution is the following,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x ) = \\frac{1}{\\beta(a,b)} x^{a-1} (1-x)^{b-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\beta(a,b) = \\int_0^1 x^{a-1} (1-x)^{b-1} dx\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Note that $a=b=1$ yields the uniform distribution. In the \n",
    "special case for integers where $0\\le k\\le n$, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\int_0^1 \\binom{n}{k}x^k (1-x)^{n-k} dx = \\frac{1}{n+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To get this result without calculus, we can use an experiment by\n",
    "Thomas Bayes.  Start with $n$ white balls and one gray ball. Uniformly at\n",
    "random, toss them onto the unit interval. Let $X$ be the number of white balls\n",
    "to the left of the gray ball. Thus, $X\\in \\lbrace 0,1,\\ldots,n \\rbrace$. To\n",
    "compute $\\mathbb{P}(X=k)$, we condition on the probability of the position $B$\n",
    "of the gray ball, which is uniformly distributed over the unit interval\n",
    "($f(p)=1$). Thus, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(X=k) = \\int_0^1 \\mathbb{P}(X=k\\vert B=p) f(p) dp = \\int_0^1 \\binom{n}{k}p^k (1-p)^{n-k} dp\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, consider a slight variation on the experiment where we start\n",
    "with $n+1$ white balls and again toss them onto the unit interval and then\n",
    "later choose one ball at random to color gray. Using the same $X$ as before, by\n",
    "symmetry, because any one of the $n+1$ balls is equally likely to be chosen, we\n",
    "have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(X=k)=\\frac{1}{n+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " for $k\\in \\lbrace 0,1,\\ldots,n \\rbrace$. Both situations describe the\n",
    "same problem because it does not matter whether we paint the ball before or\n",
    "after we throw it. Setting the last two equations equal gives the desired\n",
    "result without using calculus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\int_0^1 \\binom{n}{k}p^k (1-p)^{n-k} dp =  \\frac{1}{n+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows where to get the Beta distribution from the `scipy` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "x = beta(1,1) # create random variable object\n",
    "print(x.cdf(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this experiment, it is not too surprising that there is an intimate\n",
    "relationship between the Beta distribution and binomial random variables.\n",
    "Suppose we want to estimate the probability of heads for coin-tosses using\n",
    "Bayesian inference. Using this approach, all unknown quantities are treated as\n",
    "random variables.  In this case, the probability of heads ($p$) is the unknown\n",
    "quantity that requires a *prior* distribution. Let us choose the Beta\n",
    "distribution as the prior distribution, $\\texttt{Beta}(a,b)$. Then,\n",
    "conditioning on $p$, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X\\vert p \\sim \\texttt{binom}(n,p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " which says that $X$ is conditionally  distributed as a binomial. To \n",
    "get the posterior probability, $f(p\\vert X=k)$, we have the following\n",
    "Bayes rule,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(p\\vert X=k) = \\frac{\\mathbb{P}(X=k\\vert p)f(p)}{\\mathbb{P}(X=k)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " with the corresponding denominator,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(X=k) = \\int_0^1 \\binom{n}{k}p^k (1-p)^{n-k}f(p) dp\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that unlike with our experiment before, $f(p)$ is not constant.\n",
    "Without substituting in all of the distributions,  we observe that the\n",
    "posterior is a function of $p$ which means that everything else that is not a\n",
    "function of $p$ is a constant.  This gives,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(p\\vert X=k) \\propto p^{a+k-1} (1-p)^{b+n-k-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " which is another Beta distribution with parameters $a+k,b+n-k$. This\n",
    "special relationship in which the beta prior probability distribution on $p$ on\n",
    "data that are conditionally binomial distributed  yields the posterior that is\n",
    "also binomial distributed is known as *conjugacy*. We say that the Beta\n",
    "distribution is the conjugate prior of the binomial distribution."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
