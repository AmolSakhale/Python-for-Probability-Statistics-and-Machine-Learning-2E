{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Expectation and Mean Squared Error\n",
    "\n",
    "In this section, we work through a detailed example using conditional\n",
    "expectation and optimization methods.  Suppose we have two fair six-sided dice\n",
    "($X$ and $Y$) and we want to measure the sum of the two variables as $Z=X+Y$.\n",
    "Further, let's suppose that given $Z$, we want the best estimate of $X$ in the\n",
    "mean-squared-sense. Thus, we want to minimize the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J(\\alpha) = \\sum ( x - \\alpha z )^2 \\mathbb{P}(x,z)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " where $\\mathbb{P}$ is the probability mass function for this problem.\n",
    "The idea is that when we have solved this problem, we will have a function of\n",
    "$Z$ that is going to be the minimum MSE  estimate of $X$.  We can substitute in\n",
    "for $Z$ in $J$ and get:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J(\\alpha) = \\sum ( x - \\alpha (x+y) )^2 \\mathbb{P}(x,y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Let's work out the steps in Sympy in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sympy as S\n",
    "from sympy.stats import density, E, Die\n",
    "\n",
    "x=Die('D1',6)     # 1st six sided die\n",
    "y=Die('D2',6)     # 2nd six sides die\n",
    "a=S.symbols('a')\n",
    "z = x+y           # sum of 1st and 2nd die\n",
    "J = E((x-a*(x+y))**2) # expectation\n",
    "print(S.simplify(J))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " With all that setup we can now use basic calculus to minimize the\n",
    "objective function $J$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sol,=S.solve(S.diff(J,a),a) # using calculus to minimize\n",
    "print(sol) # solution is 1/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Programming Tip.**\n",
    "\n",
    "Sympy has a `stats` module that can do some basic work with expressions\n",
    "involving probability densities and expectations. The above code uses its `E`\n",
    "function to compute the expectation.\n",
    "\n",
    "\n",
    "\n",
    " This says that $z/2$ is the MSE estimate of $X$ given $Z$ which means\n",
    "geometrically (interpreting the MSE as a squared distance weighted by the\n",
    "probability mass function) that $z/2$ is as *close* to $x$ as we are going to\n",
    "get for a given $z$.\n",
    "\n",
    "Let's look at the same problem using the conditional expectation operator $\n",
    "\\mathbb{E}(\\cdot|z) $ and apply it to our definition of $Z$. Then"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}(z|z)=\\mathbb{E}(x+y|z)=\\mathbb{E}(x|z)+\\mathbb{E}(y|z)=z\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " using the linearity of the expectation. Now, since by the\n",
    "symmetry of the problem (i.e., two identical die), we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}(x|z)=\\mathbb{E}(y|z)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we can plug this in and solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "2 \\mathbb{E}(x|z)=z\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " which once again gives,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}(x|z)  =\\frac{z}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from numpy import arange,array\n",
    "from matplotlib.pylab import subplots, cm\n",
    "from sympy import Integer\n",
    "fig,ax = subplots()\n",
    "v = arange(1,7) + arange(1,7)[:,None]\n",
    "foo=lambda i: density(z)[Integer(i)].evalf() # some tweaks to get a float out\n",
    "Zmass=array(list(map(foo,v.flat)),dtype=float).reshape(6,6)\n",
    "\n",
    "pc=ax.pcolor(arange(1,8),arange(1,8),Zmass,cmap=cm.gray)\n",
    "_=ax.set_xticks([(i+0.5) for i in range(1,7)])\n",
    "_=ax.set_xticklabels([str(i) for i in range(1,7)])\n",
    "_=ax.set_yticks([(i+0.5) for i in range(1,7)])\n",
    "_=ax.set_yticklabels([str(i) for i in range(1,7)])\n",
    "for i in range(1,7):\n",
    "    for j in range(1,7):\n",
    "        _=ax.text(i+.5,j+.5,str(i+j),fontsize=18,fontweight='bold',color='goldenrod')\n",
    "\n",
    "_=ax.set_title(r'Probability Mass for $Z$',fontsize=18)    \n",
    "_=ax.set_xlabel('$X$ values',fontsize=18)\n",
    "_=ax.set_ylabel('$Y$ values',fontsize=18);\n",
    "cb=fig.colorbar(pc)\n",
    "_=cb.ax.set_title(r'Probability',fontsize=12)\n",
    "fig.savefig('fig-probability/Conditional_expectation_MSE_001.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:FIGURE: [fig-probability/Conditional_expectation_MSE_001.png, width=500 frac=0.85] The values of $Z$ are in yellow with the corresponding values for $X$ and $Y$ on the axes. The gray scale colors indicate the underlying joint probability density. <div id=\"fig:Conditional_expectation_MSE_001\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:Conditional_expectation_MSE_001\"></div>\n",
    "\n",
    "<p>The values of $Z$ are in yellow with the corresponding values for $X$ and $Y$ on the axes. The gray scale colors indicate the underlying joint probability density.</p>\n",
    "<img src=\"fig-probability/Conditional_expectation_MSE_001.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    " which is equal to the estimate we just found by minimizing the MSE.\n",
    "Let's explore this further with [Figure](#fig:Conditional_expectation_MSE_001).  [Figure](#fig:Conditional_expectation_MSE_001) shows the values of $Z$ in yellow with\n",
    "the corresponding values for $X$ and $Y$ on the axes.  Suppose $z=2$, then the\n",
    "closest $X$ to this is $X=1$, which is what $\\mathbb{E}(x|z)=z/2=1$ gives. What\n",
    "happens when $Z=7$? In this case, this value is spread out diagonally along the\n",
    "$X$ axis so if $X=1$, then $Z$ is 6 units away, if $X=2$, then $Z$ is 5 units\n",
    "away and so on.\n",
    "\n",
    "Now, back to the original question, if we had $Z=7$ and we wanted\n",
    "to get as close as we could to this using $X$, then why not choose\n",
    "$X=6$ which is only one unit away from $Z$? The problem with doing\n",
    "that is $X=6$ only occurs 1/6 of the time, so we are not likely to\n",
    "get it right the other 5/6 of the time. So, 1/6 of the time we are\n",
    "one unit away but 5/6 of the time we are much more than one unit\n",
    "away. This means that the MSE score is going to be worse. Since\n",
    "each value of $X$ from 1 to 6 is equally likely, to play it safe,\n",
    "we choose $7/2$ as the estimate, which is what the conditional\n",
    "expectation suggests.\n",
    "\n",
    "We can check this claim with samples using Sympy below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy import stats\n",
    "# Eq constrains Z\n",
    "samples_z7 = lambda : stats.sample(x, S.Eq(z,7)) \n",
    "#using 6 as an estimate\n",
    "mn= np.mean([(6-samples_z7())**2 for i in range(100)]) \n",
    "#7/2 is the MSE estimate\n",
    "mn0= np.mean([(7/2.-samples_z7())**2 for i in range(100)]) \n",
    "print('MSE=%3.2f using 6 vs MSE=%3.2f using 7/2 ' % (mn,mn0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Programming Tip.**\n",
    "\n",
    "The `stats.sample(x, S.Eq(z,7))` function call samples the `x` variable subject\n",
    "to a condition on the `z` variable. In other words, it generates random samples\n",
    "of `x` die, given that the sum of the outcomes of that die and the `y` die add\n",
    "up to `z==7`.\n",
    "\n",
    "\n",
    "\n",
    " Please run the above code repeatedly until you are convinced that the\n",
    "$\\mathbb{E}(x|z)$ gives the lower MSE every time.  To push this reasoning,\n",
    "let's consider the case where the die is so biased so that the outcome of `6`\n",
    "is ten times more probable than any of the other outcomes. That is,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{P}(6) = 2/3\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " whereas $\\mathbb{P}(1)=\\mathbb{P}(2)=\\ldots=\\mathbb{P}(5)=1/15$.\n",
    "We can explore this using Sympy as in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# here 6 is ten times more probable than any other outcome\n",
    "x=stats.FiniteRV('D3',{1:1/15., 2:1/15., \n",
    "                       3:1/15., 4:1/15.,\n",
    "                       5:1/15., 6:2/3.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As before, we construct the sum of the two dice, and plot the\n",
    "corresponding probability mass function in [Figure](#fig:Conditional_expectation_MSE_002).  As compared with [Figure](#fig:Conditional_expectation_MSE_001), the probability mass has been shifted\n",
    "away from the smaller numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = x + y\n",
    "foo=lambda i: density(z)[S.Integer(i)].evalf() # some tweaks to get a float out\n",
    "v = np.arange(1,7) + np.arange(1,7)[:,None]\n",
    "Zmass=np.array(list(map(foo,v.flat)),dtype=float).reshape(6,6)\n",
    "\n",
    "from matplotlib.pylab import subplots, cm\n",
    "fig,ax=subplots()\n",
    "pc=ax.pcolor(np.arange(1,8),np.arange(1,8),Zmass,cmap=cm.gray)\n",
    "_=ax.set_xticks([(i+0.5) for i in range(1,7)])\n",
    "_=ax.set_xticklabels([str(i) for i in range(1,7)])\n",
    "_=ax.set_yticks([(i+0.5) for i in range(1,7)])\n",
    "_=ax.set_yticklabels([str(i) for i in range(1,7)])\n",
    "for i in range(1,7):\n",
    "    for j in range(1,7):\n",
    "        _=ax.text(i+.5,j+.5,str(i+j),fontsize=18,fontweight='bold',color='goldenrod')\n",
    "\n",
    "_=ax.set_title(r'Probability Mass for $Z$; Nonuniform Case',fontsize=13)    \n",
    "_=ax.set_xlabel('$X$ values',fontsize=18)\n",
    "_=ax.set_ylabel('$Y$ values',fontsize=18);\n",
    "cb=fig.colorbar(pc)\n",
    "_=cb.ax.set_title(r'Probability',fontsize=10)\n",
    "fig.savefig('fig-probability/Conditional_expectation_MSE_002.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:FIGURE: [fig-probability/Conditional_expectation_MSE_002.png, width=500 frac=0.85] The values of $Z$ are in yellow with the corresponding values for $X$ and $Y$ on the axes.  <div id=\"fig:Conditional_expectation_MSE_002\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:Conditional_expectation_MSE_002\"></div>\n",
    "\n",
    "<p>The values of $Z$ are in yellow with the corresponding values for $X$ and $Y$ on the axes.</p>\n",
    "<img src=\"fig-probability/Conditional_expectation_MSE_002.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "Let's see what the conditional expectation says about how we can estimate $X$\n",
    "from $Z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "E(x, S.Eq(z,7)) # conditional expectation E(x|z=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Now that we have $\\mathbb{E}(x|z=7) = 5$, we can generate\n",
    "samples as before and see if this gives the minimum MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_z7 = lambda : stats.sample(x, S.Eq(z,7)) \n",
    "#using 6 as an estimate\n",
    "mn= np.mean([(6-samples_z7())**2 for i in range(100)]) \n",
    "#5 is the MSE estimate\n",
    "mn0= np.mean([(5-samples_z7())**2 for i in range(100)]) \n",
    "print('MSE=%3.2f using 6 vs MSE=%3.2f using 5 ' % (mn,mn0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a simple example, we have emphasized the connection between minimum mean\n",
    "squared error problems and conditional expectation. Hopefully, the last two\n",
    "figures helped expose the role of the probability density.  Next, we'll\n",
    "continue revealing  the true power of the conditional expectation as we\n",
    "continue to develop corresponding geometric intuition."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
